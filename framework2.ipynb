{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-cff2fc6bdee3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLSTM\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mEmbedding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDense\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDropout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizers\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mAdam\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mModel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mload_model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallbacks\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mModelCheckpoint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mEarlyStopping\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mCSVLogger\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mInput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from eval_utils import calculate_results, prepare_for_evaluation, generate_report, encode_sequences, encode_output\n",
    "from dataloader import *\n",
    "from  config_translator import *\n",
    "from data_processor import preprocess_data\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = DataLoader(config_mixed_coco14_coco14_glove)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data=preprocess_data(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def data_generator(train_input, input_tokenizer, max_input_length, train_output, output_tokenizer, max_output_length,\n",
    "#                    output_vocab_size, batch_size=64):\n",
    "#     while 1:\n",
    "#         count = 0\n",
    "# \n",
    "#         while 1:\n",
    "#             if count >= len(train_output):\n",
    "#                 count = 0\n",
    "# \n",
    "#             input_seq = list()\n",
    "#             output_seq = list()\n",
    "#             for i in range(count, min(len(train_input), count+batch_size)):\n",
    "#                 input, output = train_input[i], train_output[i]\n",
    "#                 input_seq.append(input)\n",
    "#                 output_seq.append(output)\n",
    "#             input_seq = encode_sequences(input_tokenizer, max_input_length, input_seq)\n",
    "#             output_seq = encode_sequences(output_tokenizer, max_output_length, output_seq)\n",
    "#             output_seq = encode_output(output_seq, output_vocab_size)\n",
    "# \n",
    "#             count = count + batch_size\n",
    "# \n",
    "#             input_seq = np.array(input_seq)\n",
    "#             output_seq = np.array(output_seq)\n",
    "#             output_seq = output_seq.reshape((output_seq.shape[0], output_seq.shape[1],output_vocab_size))\n",
    "#             import tensorflow as tf\n",
    "#             with tf.device('/cpu:0'):\n",
    "#                 input_seq = tf.convert_to_tensor(input_seq, np.uint8)\n",
    "#                 output_seq = tf.convert_to_tensor(output_seq, np.uint8)\n",
    "#             yield [input_seq, output_seq]\n",
    "\n",
    "def generate_batch(X,y , max_input_length, max_output_length, num_decoder_tokens,batch_size):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_input_length),dtype=np.float32)\n",
    "            decoder_input_data = np.zeros((batch_size, max_output_length),dtype=np.float32)\n",
    "            decoder_target_data = np.zeros((batch_size, max_output_length, num_decoder_tokens),dtype=np.float32)\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                encoder_input_data[i] = input_text # encoder input seq\n",
    "                decoder_input_data[i] = target_text # decoder input seq\n",
    "                for t, word in enumerate(target_text):\n",
    "                    if word != 0:\n",
    "                        decoder_target_data[i, t,word] = 1\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n",
    "\n",
    "\n",
    "def encoder_model(num_words_output,LSTM_NODES):\n",
    "    decoder_state_input_h = Input(shape=(LSTM_NODES,))\n",
    "    decoder_state_input_c = Input(shape=(LSTM_NODES,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_inputs_single = Input(shape=(1,))\n",
    "    decoder_embedding = Embedding(num_words_output, LSTM_NODES)\n",
    "    decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "    decoder_lstm = LSTM(LSTM_NODES, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [h, c]\n",
    "    decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs_single] + decoder_states_inputs,[decoder_outputs] + decoder_states)\n",
    "    return encoder_model, decoder_model\n",
    "\n",
    "def translate_sentence(input_seq, word2idx_inputs, word2idx_outputs, max_out_len, encoder_model, decoder_model):\n",
    "    idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "    idx2word_target = {v:k for k, v in word2idx_outputs.items()}\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "    output_sentence = []\n",
    "\n",
    "    for _ in range(max_out_len):\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        target_seq[0, 0] = idx\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return ' '.join(output_sentence)\n",
    "\n",
    "\n",
    "class ModelImpl:\n",
    "    def __init__(self, data):\n",
    "        self.data=data\n",
    "        def define_model_glove(num_words, embedding_matrix, max_input_len,max_out_len, num_words_output, EMBEDDING_SIZE, LSTM_NODES=256):\n",
    "            encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
    "            embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)\n",
    "            x = embedding_layer(encoder_inputs_placeholder)\n",
    "            encoder = LSTM(LSTM_NODES, return_state=True)\n",
    "\n",
    "            encoder_outputs, h, c = encoder(x)\n",
    "            encoder_states = [h, c]\n",
    "            decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
    "\n",
    "            decoder_embedding = Embedding(num_words_output, LSTM_NODES)\n",
    "            decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "            decoder_lstm = LSTM(LSTM_NODES, return_sequences=True, return_state=True)\n",
    "            decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "            decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "            decoder_outputs = decoder_dense(decoder_outputs)\n",
    "            model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)\n",
    "            return model\n",
    "\n",
    "        self.model = define_model_glove(self.data.num_words, self.data.embedding_matrix_input,\n",
    "                                        self.data.max_input_length, self.data.max_output_length,\n",
    "                                        self.data.num_words_output, glove[\"embedings_dim\"], 256  )\n",
    "        self.model.compile(\n",
    "            optimizer=self.optimizer(),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        self.model.summary()\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        # model.optimizer.lr = 0.001\n",
    "        self.epochs = 100\n",
    "        self.batch_size=200\n",
    "        self.steps = len(self.data.output_sentences_list_with_start) // self.batch_size\n",
    "\n",
    "    def optimizer(self):\n",
    "        return Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    def train(self):\n",
    "        model_weights_path=\"./\" + self.data.configuration[\"data_name\"] + self.data.configuration[\"model_save_dir\"]\n",
    "        if self.data.configuration[\"train_model\"]:\n",
    "            es = EarlyStopping(monitor='loss', min_delta=0.001, patience=3)\n",
    "            filepath = model_weights_path + self.data.configuration[\"model_save_path\"]\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True,\n",
    "                                         mode='min', save_weights_only=False)\n",
    "            callbacks_list = [checkpoint, es, CSVLogger(\"./\" + self.data.configuration[\"data_name\"] +'/logs.csv', separator=\",\", append=True),]\n",
    "            if self.data.configuration[\"continue_training\"]:\n",
    "                self.model = load_model(filepath)\n",
    "                print(\"New model loaded\")\n",
    "\n",
    "            train_generator = generate_batch(self.data.encoder_input_sequences, self.data.decoder_input_sequences,\n",
    "                                             self.data.max_input_length, self.data.max_output_length,\n",
    "                                             self.data.num_words_output, batch_size= self.batch_size)\n",
    "            self.model.fit(train_generator,\n",
    "                epochs=self.epochs,\n",
    "                steps_per_epoch=self.steps,\n",
    "                callbacks=[callbacks_list],\n",
    "                verbose=1,\n",
    "            )\n",
    "            if self.data.configuration[\"save_model\"]:\n",
    "                writepath = model_weights_path+ \"/\"+'model' + '.h5'\n",
    "                self.model.save(writepath)\n",
    "                self.model.save_weights(model_weights_path\n",
    "                                        + self.data.configuration[\"model_save_path\"])\n",
    "\n",
    "    def evaluate(self):\n",
    "        model_weights_path=\"./\" + self.data.configuration[\"data_name\"] + self.data.configuration[\"model_save_dir\"]\n",
    "        print(\"Model loaded from file\")\n",
    "        self.model.load_weights(model_weights_path + self.data.configuration[\"model_save_path\"])\n",
    "        expected, results = prepare_for_evaluation(self.data, self.model)\n",
    "        out = calculate_results(expected, results, self.data.configuration)\n",
    "        print(out)\n",
    "model=ModelImpl(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_report(general[\"results_directory\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}